{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_calls(model_name: str, test_set: str):\n",
    "    data_dir = f'answers/{model_name}/{test_set}'\n",
    "    data_files = os.listdir(data_dir)\n",
    "    data_files = [f for f in data_files if f.endswith('.json')]\n",
    "    ret = {}\n",
    "    for data_file in data_files:\n",
    "        qid = int(data_file.split('_')[0])\n",
    "        with open(os.path.join(data_dir, data_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        if not data['answer_generation']['valid_data']:\n",
    "            continue\n",
    "        if 'train_messages' not in data[\"answer_generation\"]:\n",
    "            print(data_dir, data_file)\n",
    "            ret[qid] = []\n",
    "            continue\n",
    "        if len(data[\"answer_generation\"][\"train_messages\"]) == 0:\n",
    "            ret[qid] = []\n",
    "        else:\n",
    "            apis = []\n",
    "            history = data[\"answer_generation\"][\"train_messages\"][-1]\n",
    "            for utt, utt_next in zip(history[:-1], history[1:]):\n",
    "                if utt['role'] != 'assistant':\n",
    "                    continue\n",
    "                if 'tool_calls' not in utt:\n",
    "                    continue\n",
    "                for tool in utt['tool_calls']:\n",
    "                    assert 'function' in tool\n",
    "                    assert 'name' in tool['function']\n",
    "                    if tool['function']['name'].lower() == 'finish':\n",
    "                        continue\n",
    "                    apis.append(tool['function']['name'])\n",
    "            # apis = list(set(apis))\n",
    "            apis = list(apis)\n",
    "            ret[qid] = apis\n",
    "    return ret\n",
    "\n",
    "def extract_model_messages(model_name: str, test_set: str) -> dict[int, list[dict]]:\n",
    "    data_dir = f'answers/{model_name}/{test_set}'\n",
    "    data_files = os.listdir(data_dir)\n",
    "    data_files = [f for f in data_files if f.endswith('.json')]\n",
    "    ret = {}\n",
    "    for data_file in data_files:\n",
    "        qid = int(data_file.split('_')[0])\n",
    "        with open(os.path.join(data_dir, data_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        if not data['answer_generation']['valid_data']:\n",
    "            continue\n",
    "        if len(data[\"answer_generation\"][\"train_messages\"]) == 0:\n",
    "            ret[qid] = []\n",
    "        else:\n",
    "            ret[qid] = data[\"answer_generation\"][\"train_messages\"][-1]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuccCalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_success(message: dict):\n",
    "    assert message['role'] == 'tool'\n",
    "    try:\n",
    "        tool_response = json.loads(message['content'])\n",
    "    except:\n",
    "        if not message['content'].startswith('{\"error\": \"\", \"response\": ') and message['content'].startswith('{\"error\": \"'):\n",
    "            tool_response = json.loads(message['content'] + '\"}')\n",
    "\n",
    "    if message['content'].startswith('{\"error\": \"\", \"response\": ') and  message['content']:\n",
    "        return True\n",
    "    if tool_response['error'] != '':\n",
    "        return False\n",
    "    response = tool_response['response']\n",
    "    if isinstance(response, dict):\n",
    "        if 'status' in response:\n",
    "            if response['status'] == 400:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            return True\n",
    "    elif isinstance(response, list) or isinstance(response, bool) or isinstance(response, int):\n",
    "        return True\n",
    "    if 'wrong' in response or 'error' in response or 'is empty' in response or response.startswith('Please'):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def success_count(messages: list[dict]):\n",
    "    cnt = 0\n",
    "    success_cnt = 0\n",
    "    for message, next_message in zip(messages[:-1], messages[1:]):\n",
    "        if message['role'] != 'assistant':\n",
    "            continue\n",
    "        if 'tool_calls' not in message or len(message['tool_calls']) == 0:\n",
    "            continue\n",
    "        tool_call = message['tool_calls'][0]\n",
    "        if tool_call['function']['name'].lower() == 'finish':\n",
    "            continue\n",
    "        cnt += 1\n",
    "        if check_success(next_message):\n",
    "            success_cnt += 1\n",
    "    return cnt, success_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_content(message: dict) -> str:\n",
    "    try:\n",
    "        tool_response = json.loads(message['content'])\n",
    "    except:\n",
    "        return message['content'][len('{\"error\": \"\", \"response\": '):]\n",
    "    response = tool_response['response']\n",
    "    return str(response)\n",
    "\n",
    "def lcs(str1: str, str2: str):\n",
    "    m, n = len(str1), len(str2)\n",
    "    # 创建一个(m+1) x (n+1)的矩阵，dp[i][j]存储str1前i个字符与str2前j个字符的LCS长度\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # 填充dp表\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    # 构建LCS字符串\n",
    "    lcs_str = []\n",
    "    i, j = m, n\n",
    "    while i > 0 and j > 0:\n",
    "        if str1[i - 1] == str2[j - 1]:\n",
    "            lcs_str.append(str1[i - 1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i - 1][j] > dp[i][j - 1]:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "\n",
    "    # 反转列表并返回LCS字符串\n",
    "    lcs_str.reverse()\n",
    "    return ''.join(lcs_str)\n",
    "\n",
    "def calc_contribution(message: dict, finish_content: str, threshold: float = 0.3):\n",
    "    response = get_content(message)\n",
    "    if len(response) == 0:\n",
    "        return 0\n",
    "    # calculate the longest common subsequence\n",
    "    lcs_str = lcs(response, finish_content)\n",
    "    ratio = len(lcs_str) / len(response)\n",
    "    # return ratio\n",
    "    if ratio < threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
